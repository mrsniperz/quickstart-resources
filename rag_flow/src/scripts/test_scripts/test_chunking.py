#!/usr/bin/env python3
"""
æ¨¡å—åç§°: test_chunking
åŠŸèƒ½æè¿°: RAG Flowæ–‡æ¡£åˆ†å—åŠŸèƒ½ä¸“ç”¨æµ‹è¯•è„šæœ¬ï¼Œé‡ç‚¹æµ‹è¯•recursive_chunkerçš„åˆ†å—æ•ˆæœ
åˆ›å»ºæ—¥æœŸ: 2025-06-19
ä½œè€…: Sniperz
ç‰ˆæœ¬: v1.0.0

ä½¿ç”¨è¯´æ˜:
    python test_chunking.py --demo                    # è¿è¡Œæ¼”ç¤ºæ¨¡å¼
    python test_chunking.py -i document.txt          # æµ‹è¯•æ–‡ä»¶
    python test_chunking.py -t "æµ‹è¯•æ–‡æœ¬"             # æµ‹è¯•ç›´æ¥è¾“å…¥çš„æ–‡æœ¬
    python test_chunking.py --performance             # æ€§èƒ½æµ‹è¯•æ¨¡å¼
    python test_chunking.py -s recursive --chunk-size 500  # è‡ªå®šä¹‰å‚æ•°

æ”¯æŒçš„åˆ†å—ç­–ç•¥:
    - recursive: é€’å½’å­—ç¬¦åˆ†å—å™¨ï¼ˆé»˜è®¤ï¼Œé‡ç‚¹æµ‹è¯•ï¼‰
    - semantic: è¯­ä¹‰åˆ†å—å™¨
    - structure: ç»“æ„åˆ†å—å™¨
    - aviation_maintenance: èˆªç©ºç»´ä¿®æ–‡æ¡£åˆ†å—å™¨
    - aviation_regulation: èˆªç©ºè§„ç« åˆ†å—å™¨
    - aviation_standard: èˆªç©ºæ ‡å‡†åˆ†å—å™¨
    - aviation_training: èˆªç©ºåŸ¹è®­åˆ†å—å™¨
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    # ç›´æ¥å¯¼å…¥éœ€è¦çš„æ¨¡å—ï¼Œé¿å…å¤æ‚ä¾èµ–
    from core.document_processor.chunking.recursive_chunker import RecursiveCharacterChunker
    from core.document_processor.chunking.chunking_engine import ChunkType, ChunkMetadata, TextChunk

    # å°è¯•å¯¼å…¥æ—¥å¿—ç®¡ç†å™¨ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ ‡å‡†logging
    try:
        from utils.logger import SZ_LoggerManager
        USE_CUSTOM_LOGGER = True
    except ImportError:
        USE_CUSTOM_LOGGER = False

except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨RAG Flowé¡¹ç›®çš„srcç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    print(f"å½“å‰è·¯å¾„: {os.getcwd()}")
    print(f"é¡¹ç›®æ ¹è·¯å¾„: {project_root}")
    print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    print("1. ç¡®ä¿åœ¨ rag_flow/src ç›®å½•ä¸‹è¿è¡Œè„šæœ¬")
    print("2. æ£€æŸ¥chunkingæ¨¡å—æ˜¯å¦å®Œæ•´")
    print("3. å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…")
    sys.exit(1)


class ChunkingTester:
    """
    æ–‡æ¡£åˆ†å—æµ‹è¯•å™¨

    ä¸“é—¨æµ‹è¯•RecursiveCharacterChunkerçš„åˆ†å—æ•ˆæœï¼ŒåŒ…æ‹¬ï¼š
    - é€’å½’åˆ†å—ç­–ç•¥æµ‹è¯•
    - åˆ†å—æ•ˆæœå¯è§†åŒ–
    - æ€§èƒ½ç»Ÿè®¡åˆ†æ
    - å‚æ•°è°ƒä¼˜å»ºè®®
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨

        Args:
            config: åˆ†å—å™¨é…ç½®å‚æ•°
        """
        self.config = config or {}

        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        if USE_CUSTOM_LOGGER:
            self.logger = SZ_LoggerManager.setup_logger(
                logger_name="chunking_tester",
                log_file="chunking_test.log",
                level=logging.INFO
            )
        else:
            logging.basicConfig(level=logging.INFO)
            self.logger = logging.getLogger("chunking_tester")

        try:
            # ç›´æ¥åˆ›å»ºRecursiveCharacterChunkerå®ä¾‹
            self.chunker = RecursiveCharacterChunker(self.config)
            self.logger.info("é€’å½’åˆ†å—å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"é€’å½’åˆ†å—å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def test_chunking(self, text: str, metadata: Dict[str, Any],
                     strategy_name: Optional[str] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ†å—æµ‹è¯•

        Args:
            text: å¾…åˆ†å—çš„æ–‡æœ¬
            metadata: æ–‡æ¡£å…ƒæ•°æ®
            strategy_name: æŒ‡å®šçš„åˆ†å—ç­–ç•¥åç§°ï¼ˆæ­¤ç‰ˆæœ¬åªæ”¯æŒrecursiveï¼‰

        Returns:
            dict: æµ‹è¯•ç»“æœï¼ŒåŒ…å«åˆ†å—ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
        """
        try:
            start_time = time.time()

            # ä½¿ç”¨RecursiveCharacterChunkeræ‰§è¡Œåˆ†å—
            chunks = self.chunker.chunk_text(text, metadata)

            processing_time = time.time() - start_time

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            stats = self._calculate_statistics(chunks, processing_time, len(text))

            return {
                'chunks': chunks,
                'statistics': stats,
                'processing_time': processing_time,
                'strategy_used': 'recursive'
            }

        except Exception as e:
            self.logger.error(f"åˆ†å—æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    def _calculate_statistics(self, chunks: List, processing_time: float, 
                            original_length: int) -> Dict[str, Any]:
        """
        è®¡ç®—åˆ†å—ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            chunks: åˆ†å—ç»“æœåˆ—è¡¨
            processing_time: å¤„ç†æ—¶é—´
            original_length: åŸæ–‡é•¿åº¦
            
        Returns:
            dict: ç»Ÿè®¡ä¿¡æ¯
        """
        if not chunks:
            return {
                'chunk_count': 0,
                'total_characters': 0,
                'average_chunk_size': 0,
                'min_chunk_size': 0,
                'max_chunk_size': 0,
                'processing_speed': 0,
                'coverage_rate': 0
            }
        
        chunk_sizes = [chunk.character_count for chunk in chunks]
        total_chars = sum(chunk_sizes)
        
        return {
            'chunk_count': len(chunks),
            'total_characters': total_chars,
            'average_chunk_size': total_chars / len(chunks),
            'min_chunk_size': min(chunk_sizes),
            'max_chunk_size': max(chunk_sizes),
            'processing_speed': original_length / processing_time if processing_time > 0 else 0,
            'coverage_rate': (total_chars / original_length) * 100 if original_length > 0 else 0,
            'quality_scores': [chunk.quality_score for chunk in chunks if hasattr(chunk, 'quality_score')]
        }
    
    def visualize_chunks(self, result: Dict[str, Any], output_format: str = 'detailed') -> None:
        """
        å¯è§†åŒ–åˆ†å—ç»“æœ
        
        Args:
            result: æµ‹è¯•ç»“æœ
            output_format: è¾“å‡ºæ ¼å¼ ('detailed', 'simple', 'json')
        """
        chunks = result['chunks']
        stats = result['statistics']
        
        if output_format == 'json':
            self._output_json(result)
            return
        
        # è¾“å‡ºæ ‡é¢˜
        print("\n" + "="*80)
        print(f"ğŸ” RAG Flow æ–‡æ¡£åˆ†å—æµ‹è¯•ç»“æœ")
        print(f"ğŸ“Š ç­–ç•¥: {result['strategy_used']}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {result['processing_time']:.3f}ç§’")
        print("="*80)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self._print_statistics(stats)
        
        if output_format == 'detailed':
            self._print_detailed_chunks(chunks)
        else:
            self._print_simple_chunks(chunks)
    
    def _print_statistics(self, stats: Dict[str, Any]) -> None:
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   åˆ†å—æ•°é‡: {stats['chunk_count']}")
        print(f"   æ€»å­—ç¬¦æ•°: {stats['total_characters']}")
        print(f"   å¹³å‡åˆ†å—å¤§å°: {stats['average_chunk_size']:.1f} å­—ç¬¦")
        print(f"   æœ€å°åˆ†å—: {stats['min_chunk_size']} å­—ç¬¦")
        print(f"   æœ€å¤§åˆ†å—: {stats['max_chunk_size']} å­—ç¬¦")
        print(f"   å¤„ç†é€Ÿåº¦: {stats['processing_speed']:.0f} å­—ç¬¦/ç§’")
        print(f"   è¦†ç›–ç‡: {stats['coverage_rate']:.1f}%")
        
        if stats['quality_scores']:
            avg_quality = sum(stats['quality_scores']) / len(stats['quality_scores'])
            print(f"   å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.3f}")
    
    def _print_detailed_chunks(self, chunks: List) -> None:
        """æ‰“å°è¯¦ç»†åˆ†å—ä¿¡æ¯"""
        print(f"\nğŸ“ è¯¦ç»†åˆ†å—ç»“æœ:")
        
        for i, chunk in enumerate(chunks, 1):
            print(f"\n--- åˆ†å— {i} ---")
            print(f"å¤§å°: {chunk.character_count} å­—ç¬¦ | è¯æ•°: {chunk.word_count}")
            
            if hasattr(chunk, 'quality_score'):
                print(f"è´¨é‡è¯„åˆ†: {chunk.quality_score:.3f}")
            
            if hasattr(chunk.metadata, 'start_position') and chunk.metadata.start_position is not None:
                print(f"ä½ç½®: {chunk.metadata.start_position}-{chunk.metadata.end_position}")
            
            # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
            content_preview = chunk.content[:200] + "..." if len(chunk.content) > 200 else chunk.content
            print(f"å†…å®¹: {content_preview}")
            
            # æ˜¾ç¤ºé‡å å†…å®¹
            if chunk.overlap_content:
                overlap_preview = chunk.overlap_content[:100] + "..." if len(chunk.overlap_content) > 100 else chunk.overlap_content
                print(f"é‡å : {overlap_preview}")
    
    def _print_simple_chunks(self, chunks: List) -> None:
        """æ‰“å°ç®€æ´åˆ†å—ä¿¡æ¯"""
        print(f"\nğŸ“‹ åˆ†å—æ¦‚è§ˆ:")
        
        for i, chunk in enumerate(chunks, 1):
            content_preview = chunk.content[:50] + "..." if len(chunk.content) > 50 else chunk.content
            quality_info = f" (è´¨é‡: {chunk.quality_score:.2f})" if hasattr(chunk, 'quality_score') else ""
            print(f"  {i:2d}. [{chunk.character_count:4d}å­—ç¬¦] {content_preview}{quality_info}")
    
    def _output_json(self, result: Dict[str, Any]) -> None:
        """è¾“å‡ºJSONæ ¼å¼ç»“æœ"""
        # è½¬æ¢chunksä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_chunks = []
        for chunk in result['chunks']:
            chunk_data = {
                'content': chunk.content,
                'character_count': chunk.character_count,
                'word_count': chunk.word_count,
                'quality_score': getattr(chunk, 'quality_score', 0.0),
                'overlap_content': chunk.overlap_content,
                'metadata': {
                    'chunk_id': chunk.metadata.chunk_id,
                    'chunk_type': chunk.metadata.chunk_type.value if hasattr(chunk.metadata.chunk_type, 'value') else str(chunk.metadata.chunk_type),
                    'start_position': chunk.metadata.start_position,
                    'end_position': chunk.metadata.end_position
                }
            }
            serializable_chunks.append(chunk_data)
        
        output = {
            'strategy_used': result['strategy_used'],
            'processing_time': result['processing_time'],
            'statistics': result['statistics'],
            'chunks': serializable_chunks
        }
        
        print(json.dumps(output, ensure_ascii=False, indent=2))
    
    def run_performance_test(self, text_sizes: List[int] = None) -> None:
        """
        è¿è¡Œæ€§èƒ½æµ‹è¯•
        
        Args:
            text_sizes: æµ‹è¯•æ–‡æœ¬å¤§å°åˆ—è¡¨ï¼ˆå­—ç¬¦æ•°ï¼‰
        """
        if text_sizes is None:
            text_sizes = [1000, 5000, 10000, 50000, 100000]
        
        print("\n" + "="*80)
        print("ğŸš€ æ€§èƒ½æµ‹è¯•æ¨¡å¼")
        print("="*80)
        
        # ç”Ÿæˆæµ‹è¯•æ–‡æœ¬
        base_text = self._get_sample_text('performance')
        
        results = []
        
        for size in text_sizes:
            # ç”ŸæˆæŒ‡å®šå¤§å°çš„æ–‡æœ¬
            test_text = (base_text * (size // len(base_text) + 1))[:size]
            
            metadata = {
                'file_name': f'performance_test_{size}.txt',
                'document_type': 'performance_test',
                'title': f'æ€§èƒ½æµ‹è¯•æ–‡æ¡£ ({size}å­—ç¬¦)'
            }
            
            print(f"\næµ‹è¯•æ–‡æœ¬å¤§å°: {size:,} å­—ç¬¦")
            
            try:
                result = self.test_chunking(test_text, metadata)
                results.append({
                    'size': size,
                    'time': result['processing_time'],
                    'chunks': result['statistics']['chunk_count'],
                    'speed': result['statistics']['processing_speed']
                })

                print(f"  å¤„ç†æ—¶é—´: {result['processing_time']:.3f}ç§’")
                print(f"  åˆ†å—æ•°é‡: {result['statistics']['chunk_count']}")
                print(f"  å¤„ç†é€Ÿåº¦: {result['statistics']['processing_speed']:.0f} å­—ç¬¦/ç§’")

            except Exception as e:
                print(f"  æµ‹è¯•å¤±è´¥: {e}")
        
        # è¾“å‡ºæ€§èƒ½æ€»ç»“
        if results:
            print(f"\nğŸ“Š æ€§èƒ½æµ‹è¯•æ€»ç»“:")
            print(f"{'æ–‡æœ¬å¤§å°':>10} {'å¤„ç†æ—¶é—´':>10} {'åˆ†å—æ•°':>8} {'é€Ÿåº¦':>12}")
            print("-" * 45)
            for r in results:
                print(f"{r['size']:>10,} {r['time']:>9.3f}s {r['chunks']:>7} {r['speed']:>10.0f}/s")
    
    def run_demo(self) -> None:
        """è¿è¡Œæ¼”ç¤ºæ¨¡å¼"""
        print("\n" + "="*80)
        print("ğŸ¯ RAG Flow é€’å½’åˆ†å—å™¨åŠŸèƒ½æ¼”ç¤º")
        print("="*80)

        demo_scenarios = [
            ('é€šç”¨æŠ€æœ¯æ–‡æ¡£', 'general'),
            ('èˆªç©ºç»´ä¿®æ‰‹å†Œ', 'aviation'),
            ('ä»£ç æ–‡æ¡£', 'code'),
            ('ç»“æ„åŒ–æ–‡æ¡£', 'structured')
        ]

        for name, text_type in demo_scenarios:
            print(f"\nğŸ”¸ æ¼”ç¤ºåœºæ™¯: {name}")
            print("-" * 40)

            text = self._get_sample_text(text_type)
            metadata = {
                'file_name': f'{text_type}_demo.txt',
                'document_type': text_type,
                'title': name
            }

            try:
                result = self.test_chunking(text, metadata)
                self.visualize_chunks(result, 'simple')
            except Exception as e:
                print(f"æ¼”ç¤ºå¤±è´¥: {e}")
    
    def _get_sample_text(self, text_type: str) -> str:
        """è·å–ç¤ºä¾‹æ–‡æœ¬"""
        samples = {
            'general': """
ç¬¬ä¸€ç«  ç³»ç»Ÿæ¶æ„è®¾è®¡

1.1 æ¦‚è¿°
æœ¬ç³»ç»Ÿé‡‡ç”¨å¾®æœåŠ¡æ¶æ„è®¾è®¡ï¼Œå…·æœ‰é«˜å¯ç”¨æ€§ã€å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§çš„ç‰¹ç‚¹ã€‚ç³»ç»Ÿä¸»è¦ç”±ä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼šç”¨æˆ·ç®¡ç†æ¨¡å—ã€æ•°æ®å¤„ç†æ¨¡å—ã€æ¥å£æœåŠ¡æ¨¡å—å’Œç›‘æ§æ¨¡å—ã€‚

1.2 æŠ€æœ¯é€‰å‹
åœ¨æŠ€æœ¯é€‰å‹æ–¹é¢ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä»¥ä¸‹æŠ€æœ¯æ ˆï¼š
- åç«¯æ¡†æ¶ï¼šSpring Boot 2.7
- æ•°æ®åº“ï¼šMySQL 8.0 + Redis 6.2
- æ¶ˆæ¯é˜Ÿåˆ—ï¼šRabbitMQ 3.9
- å®¹å™¨åŒ–ï¼šDocker + Kubernetes
- ç›‘æ§ï¼šPrometheus + Grafana

1.3 ç³»ç»Ÿç‰¹æ€§
ç³»ç»Ÿå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š
1. é«˜å¹¶å‘å¤„ç†èƒ½åŠ›ï¼Œæ”¯æŒæ¯ç§’10ä¸‡æ¬¡è¯·æ±‚
2. æ•°æ®ä¸€è‡´æ€§ä¿è¯ï¼Œé‡‡ç”¨åˆ†å¸ƒå¼äº‹åŠ¡ç®¡ç†
3. è‡ªåŠ¨æ•…éšœæ¢å¤ï¼Œå…·å¤‡å®Œå–„çš„å®¹é”™æœºåˆ¶
4. å®æ—¶ç›‘æ§å‘Šè­¦ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ
""",
            
            'aviation': """
ä»»åŠ¡1ï¼šå‘åŠ¨æœºæ—¥å¸¸æ£€æŸ¥ç¨‹åº

è­¦å‘Šï¼šåœ¨è¿›è¡Œä»»ä½•å‘åŠ¨æœºæ£€æŸ¥å‰ï¼Œå¿…é¡»ç¡®ä¿å‘åŠ¨æœºå®Œå…¨å†·å´ï¼Œå¹¶æ–­å¼€æ‰€æœ‰ç”µæºã€‚

æ­¥éª¤1ï¼šå¤–è§‚æ£€æŸ¥
æ£€æŸ¥å‘åŠ¨æœºå¤–å£³æ˜¯å¦æœ‰è£‚çº¹ã€è…èš€æˆ–å¼‚å¸¸ç£¨æŸã€‚ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹éƒ¨ä½ï¼š
- è¿›æ°”é“å’Œæ’æ°”å£
- ç‡ƒæ²¹ç®¡è·¯è¿æ¥å¤„
- ç”µæ°”çº¿æŸå›ºå®šç‚¹
- å†·å´ç³»ç»Ÿç®¡è·¯

æ­¥éª¤2ï¼šæ¶²ä½æ£€æŸ¥
æ£€æŸ¥å„ç§æ¶²ä½“çš„æ¶²ä½æ˜¯å¦åœ¨æ­£å¸¸èŒƒå›´å†…ï¼š
- å‘åŠ¨æœºæœºæ²¹æ¶²ä½
- å†·å´æ¶²æ¶²ä½
- æ¶²å‹æ²¹æ¶²ä½

æ³¨æ„ï¼šæ‰€æœ‰æ¶²ä½æ£€æŸ¥å¿…é¡»åœ¨å‘åŠ¨æœºæ°´å¹³çŠ¶æ€ä¸‹è¿›è¡Œã€‚

æ­¥éª¤3ï¼šåŠŸèƒ½æµ‹è¯•
å¯åŠ¨å‘åŠ¨æœºè¿›è¡ŒåŠŸèƒ½æµ‹è¯•ï¼Œç›‘æ§ä»¥ä¸‹å‚æ•°ï¼š
- å‘åŠ¨æœºè½¬é€Ÿ
- æ²¹å‹æŒ‡ç¤º
- æ¸©åº¦æŒ‡ç¤º
- æŒ¯åŠ¨æ°´å¹³

ä»»åŠ¡2ï¼šèºæ—‹æ¡¨æ£€æŸ¥ç¨‹åº

è­¦å‘Šï¼šèºæ—‹æ¡¨æ£€æŸ¥æ—¶å¿…é¡»ç¡®ä¿èºæ—‹æ¡¨å®Œå…¨é™æ­¢ï¼Œå¹¶è®¾ç½®å®‰å…¨è­¦ç¤ºæ ‡å¿—ã€‚
""",
            
            'code': """
# ç”¨æˆ·è®¤è¯æ¨¡å—

## æ¦‚è¿°
æœ¬æ¨¡å—æä¾›å®Œæ•´çš„ç”¨æˆ·è®¤è¯åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç™»å½•ã€æ³¨å†Œã€å¯†ç é‡ç½®ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

## ä¸»è¦ç±»å’Œæ–¹æ³•

### UserAuthenticatorç±»
```python
class UserAuthenticator:
    def __init__(self, config):
        self.config = config
        self.session_manager = SessionManager()
    
    def authenticate(self, username, password):
        \"\"\"
        ç”¨æˆ·è®¤è¯æ–¹æ³•
        
        Args:
            username (str): ç”¨æˆ·å
            password (str): å¯†ç 
            
        Returns:
            bool: è®¤è¯ç»“æœ
        \"\"\"
        user = self.get_user(username)
        if user and self.verify_password(password, user.password_hash):
            return self.create_session(user)
        return False
    
    def register_user(self, user_data):
        \"\"\"æ³¨å†Œæ–°ç”¨æˆ·\"\"\"
        # éªŒè¯ç”¨æˆ·æ•°æ®
        if not self.validate_user_data(user_data):
            raise ValidationError("ç”¨æˆ·æ•°æ®éªŒè¯å¤±è´¥")
        
        # åˆ›å»ºç”¨æˆ·è´¦æˆ·
        user = User.create(user_data)
        return user.id
```

### é…ç½®è¯´æ˜
ç³»ç»Ÿæ”¯æŒä»¥ä¸‹é…ç½®å‚æ•°ï¼š
- SESSION_TIMEOUT: ä¼šè¯è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤30åˆ†é’Ÿï¼‰
- PASSWORD_MIN_LENGTH: å¯†ç æœ€å°é•¿åº¦ï¼ˆé»˜è®¤8ä½ï¼‰
- MAX_LOGIN_ATTEMPTS: æœ€å¤§ç™»å½•å°è¯•æ¬¡æ•°ï¼ˆé»˜è®¤5æ¬¡ï¼‰
""",
            
            'structured': """
# é¡¹ç›®ç®¡ç†è§„èŒƒæ–‡æ¡£

## 1. é¡¹ç›®ç”Ÿå‘½å‘¨æœŸç®¡ç†

### 1.1 é¡¹ç›®å¯åŠ¨é˜¶æ®µ
#### 1.1.1 éœ€æ±‚åˆ†æ
- ä¸šåŠ¡éœ€æ±‚æ”¶é›†
- æŠ€æœ¯éœ€æ±‚åˆ†æ
- å¯è¡Œæ€§ç ”ç©¶

#### 1.1.2 é¡¹ç›®è§„åˆ’
- é¡¹ç›®èŒƒå›´å®šä¹‰
- æ—¶é—´è®¡åˆ’åˆ¶å®š
- èµ„æºåˆ†é…è®¡åˆ’

### 1.2 é¡¹ç›®æ‰§è¡Œé˜¶æ®µ
#### 1.2.1 å¼€å‘ç®¡ç†
- ä»£ç å¼€å‘è§„èŒƒ
- ç‰ˆæœ¬æ§åˆ¶ç®¡ç†
- ä»£ç å®¡æŸ¥æµç¨‹

#### 1.2.2 è´¨é‡æ§åˆ¶
- å•å…ƒæµ‹è¯•è¦æ±‚
- é›†æˆæµ‹è¯•æµç¨‹
- æ€§èƒ½æµ‹è¯•æ ‡å‡†

## 2. å›¢é˜Ÿåä½œè§„èŒƒ

### 2.1 æ²Ÿé€šæœºåˆ¶
- æ—¥å¸¸ç«™ä¼šåˆ¶åº¦
- å‘¨æŠ¥æ±‡æŠ¥æœºåˆ¶
- æœˆåº¦æ€»ç»“ä¼šè®®

### 2.2 æ–‡æ¡£ç®¡ç†
- æŠ€æœ¯æ–‡æ¡£ç¼–å†™è§„èŒƒ
- æ–‡æ¡£ç‰ˆæœ¬æ§åˆ¶
- çŸ¥è¯†åº“ç»´æŠ¤

## 3. é£é™©ç®¡ç†

### 3.1 é£é™©è¯†åˆ«
- æŠ€æœ¯é£é™©è¯„ä¼°
- è¿›åº¦é£é™©ç›‘æ§
- è´¨é‡é£é™©é¢„è­¦

### 3.2 åº”æ€¥é¢„æ¡ˆ
- æ•…éšœå¤„ç†æµç¨‹
- æ•°æ®å¤‡ä»½ç­–ç•¥
- ä¸šåŠ¡è¿ç»­æ€§è®¡åˆ’
""",
            
            'performance': """
ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦ä»å¤šä¸ªç»´åº¦è¿›è¡Œè€ƒè™‘å’Œå®æ–½ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§ä½“ç³»ï¼Œå®æ—¶æ”¶é›†ç³»ç»Ÿè¿è¡Œæ•°æ®ï¼ŒåŒ…æ‹¬CPUä½¿ç”¨ç‡ã€å†…å­˜å ç”¨ã€ç£ç›˜I/Oã€ç½‘ç»œå¸¦å®½ç­‰å…³é”®æŒ‡æ ‡ã€‚é€šè¿‡è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥åŠæ—¶å‘ç°æ€§èƒ½ç“¶é¢ˆï¼Œå¹¶é‡‡å–ç›¸åº”çš„ä¼˜åŒ–æªæ–½ã€‚åœ¨æ•°æ®åº“å±‚é¢ï¼Œæˆ‘ä»¬éœ€è¦ä¼˜åŒ–æŸ¥è¯¢è¯­å¥ï¼Œå»ºç«‹åˆé€‚çš„ç´¢å¼•ï¼Œåˆç†è®¾è®¡è¡¨ç»“æ„ï¼Œå¹¶è€ƒè™‘è¯»å†™åˆ†ç¦»ã€åˆ†åº“åˆ†è¡¨ç­‰ç­–ç•¥ã€‚åœ¨åº”ç”¨å±‚é¢ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç¼“å­˜æœºåˆ¶ã€å¼‚æ­¥å¤„ç†ã€è¿æ¥æ± ä¼˜åŒ–ç­‰æ–¹å¼æå‡æ€§èƒ½ã€‚åŒæ—¶ï¼Œä»£ç å±‚é¢çš„ä¼˜åŒ–ä¹Ÿä¸å®¹å¿½è§†ï¼ŒåŒ…æ‹¬ç®—æ³•ä¼˜åŒ–ã€å†…å­˜ç®¡ç†ã€å¹¶å‘æ§åˆ¶ç­‰ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿæ¶æ„çš„åˆç†è®¾è®¡ä¹Ÿæ˜¯æ€§èƒ½ä¼˜åŒ–çš„é‡è¦å› ç´ ï¼Œå¾®æœåŠ¡æ¶æ„ã€è´Ÿè½½å‡è¡¡ã€CDNåŠ é€Ÿç­‰éƒ½èƒ½æœ‰æ•ˆæå‡ç³»ç»Ÿæ€§èƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜éœ€è¦å»ºç«‹æ€§èƒ½æµ‹è¯•ä½“ç³»ï¼Œå®šæœŸè¿›è¡Œå‹åŠ›æµ‹è¯•å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨å„ç§è´Ÿè½½æ¡ä»¶ä¸‹éƒ½èƒ½ç¨³å®šè¿è¡Œã€‚
"""
        }
        
        return samples.get(text_type, samples['general'])


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="RAG Flowæ–‡æ¡£åˆ†å—åŠŸèƒ½æµ‹è¯•è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s --demo                           # è¿è¡Œæ¼”ç¤ºæ¨¡å¼
  %(prog)s -i document.txt                  # æµ‹è¯•æ–‡ä»¶
  %(prog)s -t "æµ‹è¯•æ–‡æœ¬å†…å®¹"                 # æµ‹è¯•ç›´æ¥è¾“å…¥
  %(prog)s --performance                    # æ€§èƒ½æµ‹è¯•
  %(prog)s -s recursive --chunk-size 500   # è‡ªå®šä¹‰å‚æ•°
        """
    )
    
    # è¾“å…¥å‚æ•°
    input_group = parser.add_mutually_exclusive_group()
    input_group.add_argument('--input', '-i', help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--text', '-t', help='ç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹')
    input_group.add_argument('--demo', action='store_true', help='è¿è¡Œæ¼”ç¤ºæ¨¡å¼')
    input_group.add_argument('--performance', action='store_true', help='æ€§èƒ½æµ‹è¯•æ¨¡å¼')
    
    # åˆ†å—å‚æ•°
    parser.add_argument('--strategy', '-s', default='recursive',
                       help='åˆ†å—ç­–ç•¥ (æ­¤ç‰ˆæœ¬åªæ”¯æŒrecursive)')
    parser.add_argument('--chunk-size', type=int, default=1000, help='åˆ†å—å¤§å° (é»˜è®¤: 1000)')
    parser.add_argument('--chunk-overlap', type=int, default=200, help='é‡å å¤§å° (é»˜è®¤: 200)')
    parser.add_argument('--min-chunk-size', type=int, default=100, help='æœ€å°åˆ†å—å¤§å° (é»˜è®¤: 100)')
    parser.add_argument('--max-chunk-size', type=int, default=2000, help='æœ€å¤§åˆ†å—å¤§å° (é»˜è®¤: 2000)')

    # é€’å½’åˆ†å—å™¨ç‰¹æœ‰å‚æ•°
    parser.add_argument('--separators', nargs='*', help='è‡ªå®šä¹‰åˆ†éš”ç¬¦åˆ—è¡¨')
    parser.add_argument('--keep-separator', action='store_true', help='ä¿ç•™åˆ†éš”ç¬¦')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-format', choices=['detailed', 'simple', 'json'],
                       default='detailed', help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: detailed)')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºç»“æœ')
    
    args = parser.parse_args()
    
    # æ„å»ºé…ç½®
    config = {
        'chunk_size': args.chunk_size,
        'chunk_overlap': args.chunk_overlap,
        'min_chunk_size': args.min_chunk_size,
        'max_chunk_size': args.max_chunk_size,
        'add_start_index': True
    }

    # æ·»åŠ é€’å½’åˆ†å—å™¨ç‰¹æœ‰é…ç½®
    if args.separators:
        config['separators'] = args.separators
    if args.keep_separator:
        config['keep_separator'] = True
    
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = ChunkingTester(config)
        
        if not args.quiet:
            print("ğŸš€ RAG Flow é€’å½’åˆ†å—å™¨æµ‹è¯•è„šæœ¬å¯åŠ¨")
            print(f"ğŸ“‹ å½“å‰é…ç½®: åˆ†å—å¤§å°={args.chunk_size}, é‡å ={args.chunk_overlap}")

        # æ ¹æ®å‚æ•°æ‰§è¡Œä¸åŒçš„æµ‹è¯•æ¨¡å¼
        if args.demo:
            tester.run_demo()
        elif args.performance:
            tester.run_performance_test()
        elif args.input:
            # æ–‡ä»¶è¾“å…¥æ¨¡å¼
            if not os.path.exists(args.input):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
                sys.exit(1)

            with open(args.input, 'r', encoding='utf-8') as f:
                text = f.read()

            metadata = {
                'file_name': os.path.basename(args.input),
                'file_path': args.input,
                'document_type': 'user_document',
                'title': f'ç”¨æˆ·æ–‡æ¡£: {os.path.basename(args.input)}'
            }

            result = tester.test_chunking(text, metadata)
            tester.visualize_chunks(result, args.output_format)

        elif args.text:
            # ç›´æ¥æ–‡æœ¬è¾“å…¥æ¨¡å¼
            metadata = {
                'file_name': 'direct_input.txt',
                'document_type': 'direct_input',
                'title': 'ç›´æ¥è¾“å…¥æ–‡æœ¬'
            }

            result = tester.test_chunking(args.text, metadata)
            tester.visualize_chunks(result, args.output_format)
            
        else:
            # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
            parser.print_help()
            print("\nğŸ’¡ æç¤º: ä½¿ç”¨ --demo å‚æ•°è¿è¡Œæ¼”ç¤ºæ¨¡å¼ï¼Œæˆ–ä½¿ç”¨ --help æŸ¥çœ‹è¯¦ç»†å¸®åŠ©")
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
